{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-831ec0ea4e70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;31m# Feature Matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m \u001b[0mx_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;31m# Data labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "g = tf.Graph()\n",
    "\n",
    "def logistic_regression(x_orig, y_orig, lr, epochs, batch_size, test):\n",
    "\n",
    "#     tf.reset_default_graph()\n",
    "    # Creating the One Hot Encoder \n",
    "    oneHot = OneHotEncoder(categories='auto') \n",
    "\n",
    "    with g.as_default():\n",
    "        # Encoding x_orig \n",
    "        oneHot.fit(x_orig) \n",
    "        x = oneHot.transform(x_orig).toarray() \n",
    "\n",
    "        # Encoding y_orig \n",
    "        oneHot.fit(y_orig) \n",
    "        y = oneHot.transform(y_orig).toarray() \n",
    "\n",
    "        m, n = x.shape \n",
    "\n",
    "        print(\"n: \",n)\n",
    "\n",
    "        # There are n columns in the feature matrix \n",
    "        # after One Hot Encoding. \n",
    "        X = tf.placeholder(tf.float32, [None, n], name = 'X') \n",
    "\n",
    "        # Since this is a binary classification problem, \n",
    "        # Y can take only 2 values. \n",
    "        Y = tf.placeholder(tf.float32, [None, 2], name = 'Y') \n",
    "\n",
    "        # Trainable Variable Weights \n",
    "        W = tf.Variable(tf.zeros([n, 2]), name = 'W') \n",
    "\n",
    "        # Trainable Variable Bias \n",
    "        b = tf.Variable(tf.zeros([2]), name = 'b') \n",
    "\n",
    "        # Hypothesis \n",
    "        Y_hat = tf.nn.sigmoid(tf.add(tf.matmul(X, W), b), name = 'Y_hat') \n",
    "\n",
    "        # Sigmoid Cross Entropy Cost Function \n",
    "        cost = tf.nn.sigmoid_cross_entropy_with_logits(logits = Y_hat, labels = Y, name = 'cost')\n",
    "\n",
    "        # Gradient Descent Optimizer \n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate = lr, name = \"optimizer\").minimize(cost) \n",
    "\n",
    "        # Global Variables Initializer \n",
    "        init = tf.global_variables_initializer() \n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session(graph = g) as sess:\n",
    "        # Initializing the Variables \n",
    "        sess.run(init) \n",
    "        summary_writer = tf.summary.FileWriter('./graphs/',sess.graph)\n",
    "\n",
    "        # Lists for storing the changing Cost and Accuracy in every Epoch \n",
    "        cost_history, accuracy_history = [], [] \n",
    "\n",
    "        batchs = int(np.around(n / batch_size))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            batch_start = 0\n",
    "            batch_end = batch_size - 1\n",
    "\n",
    "            cost_per_epoch = 0\n",
    "\n",
    "            for batch in range(batchs):\n",
    "                x_b = x[batch_start:batch_end]\n",
    "                y_b = y[batch_start:batch_end]\n",
    "\n",
    "                sess.run(optimizer, feed_dict = {X : x_b, Y : y_b})\n",
    "\n",
    "                # Calculating cost on current Epoch \n",
    "                y_hat, c = sess.run([Y_hat, cost], feed_dict = {X : x_b, Y : y_b}) \n",
    "\n",
    "                # Calculating accuracy on current Epoch \n",
    "                correct_prediction = tf.equal(tf.argmax(Y_hat, 1), \n",
    "                                                tf.argmax(Y, 1)) \n",
    "                accuracy = tf.reduce_mean(tf.cast(correct_prediction, \n",
    "                                                tf.float32)) \n",
    "\n",
    "                # Storing Cost and Accuracy to the history \n",
    "                if len(c) != 0:\n",
    "                    cost_history.append(sum(sum(c))) \n",
    "\n",
    "                accuracy_val = accuracy.eval({X : x_b, Y : y_b}) * 100\n",
    "\n",
    "                if ~np.isnan(accuracy_val):\n",
    "                    accuracy_history.append(accuracy_val) \n",
    "\n",
    "                # Displaying result on current Epoch \n",
    "                if batch % 50 == 0: \n",
    "                    print(\"Epoch \" + str(epoch) + \" Cost: \" \n",
    "                          + str(cost_history[-1]) \n",
    "                          + \" Accuracy: \" + str(accuracy_val)) \n",
    "\n",
    "                batch_start += batch_size\n",
    "                batch_end += batch_size\n",
    "\n",
    "        Weight = sess.run(W) # Optimized Weight \n",
    "        print('shape w ',Weight.shape)\n",
    "        Bias = sess.run(b)   # Optimized Bias \n",
    "        print('shape b ', Bias.shape)\n",
    "        \n",
    "        # Final Accuracy \n",
    "        correct_prediction = tf.equal(tf.argmax(Y_hat, 1), \n",
    "                                        tf.argmax(Y, 1)) \n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \n",
    "                                                tf.float32)) \n",
    "        print(\"\\nAccuracy:\", accuracy_history[-1], \"%\") \n",
    "\n",
    "          # Save the variables to disk.\n",
    "        save_path = saver.save(sess, \"./model/logistic.ckpt\")\n",
    "        print(\"Model saved in path: %s\" % save_path)\n",
    "        print('**********************************************')\n",
    "        # Encoding x_orig \n",
    "#         oneHot.fit(test) \n",
    "#         x_test = oneHot.transform(test).toarray() \n",
    "        y_hat = test * np.mean(Weight) + np.mean(Bias)\n",
    "        print(y_hat)\n",
    "        print(y_hat.shape)\n",
    "        \n",
    "    summary_writer.close()\n",
    "\n",
    "# Feature Matrix \n",
    "x_orig = train[train.columns[2:11]].values \n",
    "  \n",
    "# Data labels \n",
    "y_orig = train[train.columns[11]].values \n",
    "y_orig = y_orig.reshape(-1, 1)\n",
    "\n",
    "\n",
    "x_test = np.array(test.iloc[:,[2,3,4,5,6,7,8,9,10,11]])\n",
    "\n",
    "logistic_regression(x_orig = x_orig, y_orig = y_orig,lr = 0.01, batch_size = 130, epochs = 5, test = x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"passenger_survived\"\n",
    "features = [\"passenger_class\", \"passenger_sex\",\"Fare\", \"Age\"]\n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "X_test = test[features]\n",
    "y_test = test[target]\n",
    "\n",
    "def model(hu, model_dir, features):\n",
    "    # Specify the shape of the features columns, so [5,1] here\n",
    "    feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[len(features),1])]\n",
    "\n",
    "    # Build n layer DNN with hu units (hu is an array)\n",
    "    # The default optimizer is \"AdaGrad\" but we can specify another model\n",
    "    classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns,\n",
    "                                        hidden_units=hu,\n",
    "                                        n_classes=2,\n",
    "                                        optimizer=tf.train.ProximalGradientDescentOptimizer(\n",
    "                                            learning_rate=0.01,\n",
    "                                            l1_regularization_strength=0.1,\n",
    "                                            l2_regularization_strength=0.1),                                      \n",
    "                                        model_dir=model_dir)\n",
    "\n",
    "    # Define the training inputs\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": np.array(X_train)},y=np.array(y_train.values.reshape((len(y_train),1))),num_epochs=None,shuffle=True)\n",
    "    return classifier, train_input_fn\n",
    "\n",
    "classifier, train_input_fn = model([32,64,32], \"./tmp/DNN\", features)\n",
    "#Let's train\n",
    "classifier.train(input_fn=train_input_fn, steps=1000)\n",
    "\n",
    "# Define the test inputs\n",
    "def testinput(X_test, y_test):\n",
    "    test_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": np.array(X_test)},y=np.array(y_test),num_epochs=1,shuffle=False)\n",
    "    return test_input_fn\n",
    "    \n",
    "    \n",
    "my_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": np.array(test[features])},\n",
    "        y=None,\n",
    "        num_epochs=1,\n",
    "        shuffle=False)\n",
    "pred = classifier.predict(input_fn=my_input_fn)\n",
    "predictions = list(pred)\n",
    "predictions[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
